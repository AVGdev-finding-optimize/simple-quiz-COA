[
    {
        "type": "mcq",
        "question": "Trong các lớp máy tính, lớp nào đặt trọng tâm cao nhất vào 'throughput' (thông lượng) và 'availability' (tính sẵn sàng)?",
        "options": [
            "Desktop computers",
            "Server computers",
            "Embedded computers",
            "Personal mobile devices"
        ],
        "answer": 1,
        "explanation": "Máy tính chủ (Server) ưu tiên khả năng xử lý nhiều yêu cầu đồng thời (throughput) và độ tin cậy, tính sẵn sàng cao, vì chúng phục vụ nhiều người dùng qua mạng. [cite: 6616-6619]"
    },
    {
        "type": "mcq",
        "question": "Kiến trúc tập lệnh (ISA) được định nghĩa là gì?",
        "options": [
            "Giao diện giữa phần cứng và phần mềm hệ thống.",
            "Tổ chức của CPU, bao gồm ALU và các thanh ghi.",
            "Cách thức dữ liệu nhị phân được lưu trữ trong bộ nhớ.",
            "Tập hợp các vi mã thực thi các lệnh máy."
        ],
        "answer": 0,
        "explanation": "ISA (Instruction Set Architecture) là giao diện quan trọng giữa phần cứng và phần mềm. Nó định nghĩa mọi thứ mà lập trình viên (hoặc trình biên dịch) cần biết để tạo ra mã máy chính xác. [cite: 6855-6856, 6862-6867]"
    },
    {
        "type": "msq",
        "question": "Những cấp nào sau đây thuộc về 'Hệ thống phần mềm' (System software) trong các cấp của mã chương trình?",
        "options": [
            "Chương trình ngôn ngữ cấp cao (C, Java)",
            "Trình biên dịch (Compiler)",
            "Hệ điều hành (Operating System)",
            "Ngôn ngữ máy nhị phân (Binary)"
        ],
        "answer": [
            1,
            2
        ],
        "explanation": "Phần mềm hệ thống bao gồm Trình biên dịch (dịch mã HLL sang mã máy) và Hệ điều hành (quản lý I/O, bộ nhớ, tài nguyên). Mã HLL thuộc về phần mềm ứng dụng, và mã nhị phân là biểu diễn phần cứng. [cite: 6897-6902]"
    },
    {
        "type": "fitb",
        "question": "Trong hệ thống phân cấp bộ nhớ, cấp bộ nhớ có dung lượng nhỏ nhất, tốc độ truy cập nhanh nhất là ...... (Viết hoa chữ cái đầu)",
        "answer": "Thanh ghi",
        "explanation": "Theo sơ đồ phân cấp bộ nhớ, Thanh ghi (CPU Registers) ở đỉnh, có dung lượng nhỏ nhất (hàng trăm Bytes) và thời gian truy cập nhanh nhất (hàng trăm ps). [cite: 6771]"
    },
    {
        "type": "mcq",
        "question": "Theo định luật De Morgan, biểu thức (A + B) tương đương với biểu thức nào?",
        "options": [
            "A . B",
            "A + B",
            "A . B",
            "A + B"
        ],
        "answer": 2,
        "explanation": "Định luật De Morgan cho phép biến đổi giữa phép toán AND và OR với phép NOT. Quy tắc là: NOT(A + B) = (NOT A) . (NOT B). [cite: 7303, 7305]"
    },
    {
        "type": "mcq",
        "question": "Phép toán logic nào cho kết quả là 1 chỉ khi hai đầu vào có giá trị khác nhau?",
        "options": [
            "NAND",
            "NOR",
            "XOR",
            "AND"
        ],
        "answer": 2,
        "explanation": "Phép toán Exclusive-OR (XOR) trả về 1 nếu A=0, B=1 hoặc A=1, B=0. Nó trả về 0 nếu A và B giống nhau (0,0 hoặc 1,1). [cite: 7351-7356]"
    },
    {
        "type": "msq",
        "question": "Mạch logic nào sau đây được coi là mạch tuần tự (Sequential Logic)?",
        "options": [
            "Bộ giải mã (Decoder)",
            "Bộ đa hợp (Multiplexer)",
            "D-Latch",
            "D-Flip Flop"
        ],
        "answer": [
            2,
            3
        ],
        "explanation": "Mạch tuần tự là mạch có phần tử nhớ và đầu ra phụ thuộc vào trạng thái đã lưu. Latch và Flip-Flop là các phần tử nhớ cơ bản. Mux và Decoder là các mạch tổ hợp (Combinational), đầu ra chỉ phụ thuộc vào đầu vào hiện tại. [cite: 7844, 7881, 7919-7925]"
    },
    {
        "type": "mcq",
        "question": "Một máy tính có bus dữ liệu 64 bit và xung nhịp bus là 800MHz. Một thao tác đọc/ghi RAM mất 4 chu kỳ. Tốc độ truyền dữ liệu (data transfer rate) tối đa là bao nhiêu?",
        "options": [
            "1600 MBps",
            "800 MBps",
            "3200 MBps",
            "6400 MBps"
        ],
        "answer": 0,
        "explanation": "Số lượt truyền mỗi giây = 800 * 10^6 chu kỳ / 4 chu kỳ mỗi truyền = 2 * 10^8 lượt truyền. Mỗi lượt truyền 64 bit = 8 Bytes. Tốc độ = 8 Bytes * (2 * 10^8) = 16 * 10^8 B/s = 1.6 * 10^9 B/s. Đổi sang MBps (MiB/s): (1.6 * 10^9) / (1024 * 1024) ≈ 1526 MBps. Gần nhất là 1600 MBps (nếu tính 1MB = 10^6 B thì là 1600 MB/s). [cite: 7821-7829]"
    },
    {
        "type": "fitb",
        "question": "Số thập lục phân A0 (base 16) tương đương với số nhị phân ...... (8 bit).",
        "answer": "10100000",
        "explanation": "Để chuyển đổi Hex sang Binary, ta chuyển từng chữ số Hex thành 4 bit nhị phân. A (Hex) = 10 (Dec) = 1010 (Bin). 0 (Hex) = 0000 (Bin). Ghép lại ta được 10100000. [cite: 8379]"
    },
    {
        "type": "mcq",
        "question": "Sử dụng biểu diễn số nguyên có dấu 8-bit theo phương pháp bù 2 (2's Complement), giá trị -18 (thập phân) được biểu diễn là:",
        "options": [
            "10010010",
            "11101101",
            "11101110",
            "11101101"
        ],
        "answer": 2,
        "explanation": "Để biểu diễn -18 (thập phân) sang 8-bit bù 2: 1. Biểu diễn +18 (thập phân) = 00010010 (nhị phân). 2. Đảo bit (1's complement) = 11101101. 3. Cộng 1 = 11101110. [cite: 7067]"
    },
    {
        "type": "mcq",
        "question": "Một máy tính có RAM tối đa 16GB, bus dữ liệu 64-bit (kích thước slot). Cần bao nhiêu dây địa chỉ (address bus lines) để định vị một slot?",
        "options": [
            "32",
            "31",
            "34",
            "30"
        ],
        "answer": 1,
        "explanation": "Tổng dung lượng = Số lượng slot * Kích thước slot. Kích thước slot = 64 bit = 8 Bytes (2^3 Bytes). 16GB = 16 * 2^30 Bytes = 2^4 * 2^30 = 2^34 Bytes. Số lượng slot = Tổng dung lượng / Kích thước slot = 2^34 / 2^3 = 2^31 slot. Số dây địa chỉ cần = log2(Số lượng slot) = 31. [cite: 8095-8099]"
    },
    {
        "type": "mcq",
        "question": "Tốc độ của một CPU được xác định bởi công thức nào sau đây?",
        "options": [
            "Số lệnh / (Thời gian thực thi)",
            "Số chu kỳ / (Tần số xung nhịp)",
            "(Số lệnh * CPI) / (Tần số xung nhịp)",
            "Số lệnh / (Số chu kỳ * Tần số xung nhịp)"
        ],
        "answer": 2,
        "explanation": "Thời gian thực thi CPU (CPU Time) = Số lệnh * CPI * Chu kỳ xung nhịp. Vì Tần số (Clock Rate) = 1 / Chu kỳ xung nhịp, nên CPU Time = (Số lệnh * CPI) / Tần số xung nhịp. [cite: 9155-9157, 9162]"
    },
    {
        "type": "mcq",
        "question": "Một chương trình chạy trong 100 giây trên một máy tính, trong đó 60 giây dành cho tính toán nhân. Nếu tăng tốc độ bộ nhân lên 3 lần, thời gian chạy mới của chương trình là bao nhiêu?",
        "options": [
            "60 giây",
            "40 giây",
            "80 giây",
            "33.3 giây"
        ],
        "answer": 0,
        "explanation": "Áp dụng định luật Amdahl: Thời gian chạy mới = Thời gian không cải thiện + (Thời gian cải thiện / Tốc độ cải thiện). Thời gian không cải thiện = 100 - 60 = 40 giây. Thời gian cải thiện (đã tăng tốc) = 60 / 3 = 20 giây. Thời gian chạy mới = 40 + 20 = 60 giây. [cite: 9130-9143]"
    },
    {
        "type": "fitb",
        "question": "Hiện tượng một lệnh không thể thực thi trong chu kỳ xung nhịp đã định vì tài nguyên phần cứng đang được sử dụng bởi một lệnh khác được gọi là ...... hazard.",
        "answer": "Structural",
        "explanation": "Structural hazard (xung đột cấu trúc) xảy ra khi phần cứng không thể hỗ trợ tất cả các tổ hợp lệnh thực thi đồng thời trong pipeline (ví dụ: chỉ có một cổng bộ nhớ nhưng hai lệnh muốn truy cập)."
    },
    {
        "type": "mcq",
        "question": "Kiến trúc GPR (General-Purpose Register) nào chỉ cho phép truy cập bộ nhớ thông qua các lệnh LOAD và STORE?",
        "options": [
            "Register-memory (CISC)",
            "Load-store (RISC)",
            "Memory-memory",
            "Accumulator"
        ],
        "answer": 1,
        "explanation": "Kiến trúc Load-store (hay còn gọi là Register-register) là đặc trưng của RISC. Các lệnh ALU chỉ hoạt động trên thanh ghi. Dữ liệu phải được 'load' vào thanh ghi trước khi xử lý và 'store' ra bộ nhớ sau khi xử lý."
    },
    {
        "type": "msq",
        "question": "Chế độ định địa chỉ (Addressing Modes) nào sau đây thường được hỗ trợ trong các kiến trúc RISC hiện đại như MIPS?",
        "options": [
            "Displacement (Dịch chuyển)",
            "Immediate (Tức thì)",
            "Memory indirect (Gián tiếp qua bộ nhớ)",
            "Autoincrement (Tự tăng)"
        ],
        "answer": [
            0,
            1
        ],
        "explanation": "Các kiến trúc RISC như MIPS đơn giản hóa việc định địa chỉ, chủ yếu sử dụng Displacement (Base + offset), Immediate (giá trị hằng số trong lệnh) và Register indirect (là trường hợp đặc biệt của Displacement với offset = 0). Các chế độ phức tạp như Memory indirect và Autoincrement là đặc trưng của CISC (ví dụ VAX)."
    },
    {
        "type": "fitb",
        "question": "Trong kiến trúc MIPS64, thanh ghi ...... luôn có giá trị là 0.",
        "answer": "R0",
        "explanation": "Thanh ghi R0 trong MIPS được thiết kế cứng (hardwired) để luôn luôn giữ giá trị 0, rất hữu ích cho việc tổng hợp các lệnh khác (ví dụ: tạo lệnh NOP, lệnh move, hoặc so sánh với 0)."
    },
    {
        "type": "mcq",
        "question": "Một hệ thống sử dụng quy ước 'Big Endian'. Nếu lưu giá trị 32-bit 0x12345678 vào địa chỉ 1000, byte 0x12 sẽ được lưu tại địa chỉ nào?",
        "options": [
            "1000",
            "1001",
            "1002",
            "1003"
        ],
        "answer": 0,
        "explanation": "Big Endian lưu byte có trọng số cao nhất (Most Significant Byte - MSB) tại địa chỉ thấp nhất. Trong 0x12345678, 0x12 là MSB, do đó nó được lưu tại địa chỉ 1000."
    },
    {
        "type": "mcq",
        "question": "Kỹ thuật 'forwarding' (hay 'bypassing') trong pipeline được sử dụng để giải quyết loại hazard nào?",
        "options": [
            "Structural hazards",
            "Control hazards",
            "RAW (Read After Write) data hazards",
            "WAR (Write After Read) data hazards"
        ],
        "answer": 2,
        "explanation": "Forwarding giải quyết RAW hazard bằng cách chuyển tiếp kết quả từ giai đoạn EX hoặc MEM của lệnh trước về đầu vào ALU của lệnh sau, thay vì đợi lệnh trước ghi kết quả vào thanh ghi ở giai đoạn WB."
    },
    {
        "type": "mcq",
        "question": "Xét đoạn mã: LD R1, 0(R2); DSUB R4, R1, R5. Trong pipeline 5 tầng cổ điển (IF, ID, EX, MEM, WB), cần chèn bao nhiêu 'stall' (chu kỳ chờ)?",
        "options": [
            "0",
            "1",
            "2",
            "3"
        ],
        "answer": 1,
        "explanation": "Lệnh LD (Load) có dữ liệu tại cuối tầng MEM (chu kỳ 4). Lệnh DSUB cần dữ liệu này tại đầu tầng EX (chu kỳ 3). Ngay cả khi có forwarding, dữ liệu cũng không sẵn sàng kịp. Lệnh DSUB phải chờ 1 chu kỳ (stall) và chỉ bắt đầu EX ở chu kỳ 5."
    },
    {
        "type": "fitb",
        "question": "Một bộ dự đoán nhánh (branch predictor) sử dụng 2 bit trạng thái (2-bit saturating counter) sẽ thay đổi dự đoán (ví dụ từ Taken sang Not Taken) chỉ sau khi dự đoán sai ...... lần liên tiếp.",
        "answer": "2",
        "explanation": "Với sơ đồ 2-bit, cần hai lần dự đoán sai liên tiếp để chuyển từ trạng thái 'Strongly Taken' (11) sang 'Weakly Not Taken' (01), hoặc từ 'Strongly Not Taken' (00) sang 'Weakly Taken' (10). Điều này giúp tránh thay đổi dự đoán đột ngột do các nhánh bất thường (ví dụ: vòng lặp kết thúc). [cite: 9408, 9409]"
    },
    {
        "type": "msq",
        "question": "Đâu là các đặc điểm của kiến trúc VLIW (Very Long Instruction Word)?",
        "options": [
            "Lập lịch động (Dynamic scheduling) bởi phần cứng.",
            "Lập lịch tĩnh (Static scheduling) bởi trình biên dịch.",
            "Gói nhiều lệnh đơn giản, độc lập vào trong một lệnh dài.",
            "Độ phức tạp phần cứng cao hơn Superscalar."
        ],
        "answer": [
            1,
            2
        ],
        "explanation": "VLIW (và EPIC) dựa vào trình biên dịch để lập lịch tĩnh, nhóm các lệnh con (operations) có thể thực thi song song vào một 'bó' (bundle) hoặc lệnh rất dài. Phần cứng đơn giản hơn Superscalar vì không cần logic lập lịch động phức tạp. [cite: 9440-9442, 9443]"
    },
    {
        "type": "mcq",
        "question": "Kỹ thuật 'register renaming' (đổi tên thanh ghi) được sử dụng để loại bỏ loại hazard nào?",
        "options": [
            "RAW (Read After Write)",
            "WAR (Write After Read) và WAW (Write After Write)",
            "Control hazards",
            "Structural hazards"
        ],
        "answer": 1,
        "explanation": "Register renaming loại bỏ các 'name dependences' (phụ thuộc tên) chứ không phải 'true data dependences' (RAW). WAR và WAW là các name dependences, xảy ra khi các lệnh sau ghi đè lên thanh ghi mà lệnh trước cần đọc (WAR) hoặc ghi (WAW). Renaming cấp phát một thanh ghi vật lý mới để phá vỡ sự phụ thuộc giả này. [cite: 9391-9394, 9418]"
    },
    {
        "type": "mcq",
        "question": "Trong 3 loại cache miss (Compulsory, Capacity, Conflict), loại miss nào không thể tránh được ngay cả khi sử dụng cache vô hạn?",
        "options": [
            "Compulsory",
            "Capacity",
            "Conflict",
            "Tất cả đều tránh được"
        ],
        "answer": 0,
        "explanation": "Compulsory miss (miss bắt buộc) xảy ra ở lần truy cập đầu tiên đến một khối dữ liệu. Khối này chưa bao giờ có trong cache, vì vậy nó bắt buộc phải được nạp vào, bất kể cache lớn đến đâu hay có độ liên kết (associativity) như thế nào."
    },
    {
        "type": "fitb",
        "question": "Một cache sử dụng chính sách 'Write-Back'. Một bit đặc biệt được gọi là ...... được sử dụng để theo dõi xem khối cache đã bị sửa đổi hay chưa.",
        "answer": "dirty bit",
        "explanation": "Dirty bit (bit bẩn) được set (đặt thành 1) khi bộ xử lý ghi vào khối cache. Khi khối này bị thay thế, cache controller chỉ ghi ngược nó về bộ nhớ chính nếu dirty bit là 1."
    },
    {
        "type": "mcq",
        "question": "Chính sách ghi cache 'Write-Allocate' nghĩa là gì?",
        "options": [
            "Khi Write Hit, chỉ ghi vào cache.",
            "Khi Write Hit, ghi cả vào cache và bộ nhớ.",
            "Khi Write Miss, khối dữ liệu được nạp vào cache, sau đó thực hiện ghi.",
            "Khi Write Miss, dữ liệu chỉ được ghi vào bộ nhớ chính, không nạp vào cache."
        ],
        "answer": 2,
        "explanation": "Write-Allocate (cấp phát khi ghi) định nghĩa hành vi khi xảy ra Write Miss. Nó sẽ nạp khối (allocate) từ bộ nhớ vào cache, sau đó thực hiện thao tác ghi (giống như Write Hit). Ngược lại là No-Write-Allocate."
    },
    {
        "type": "mcq",
        "question": "Một CPU có 256MB RAM vật lý và kích thước trang (page size) là 4KB. Bảng trang (page table) sẽ có bao nhiêu mục (entry)?",
        "options": [
            "65536",
            "262144",
            "1048576",
            "32768"
        ],
        "answer": 0,
        "explanation": "RAM vật lý = 256MB = 2^28 Bytes. Kích thước trang = 4KB = 2^12 Bytes. Số lượng trang vật lý (physical pages) = (2^28) / (2^12) = 2^16 = 65536. Câu hỏi này đang hỏi về số lượng trang vật lý (khung trang). [Dựa trên logic phân trang chung từ C-43, C-44]"
    },
    {
        "type": "mcq",
        "question": "Mục đích chính của 'Translation Lookaside Buffer' (TLB) là gì?",
        "options": [
            "Lưu trữ các khối dữ liệu được truy cập thường xuyên.",
            "Dự đoán các nhánh rẽ.",
            "Cache (đệm) các phép dịch địa chỉ từ ảo sang vật lý.",
            "Lưu trữ các lệnh đã được giải mã."
        ],
        "answer": 2,
        "explanation": "TLB là một bộ cache đặc biệt dùng để lưu các mục bảng trang (Page Table Entries) được truy cập gần đây, giúp tăng tốc độ dịch địa chỉ ảo sang địa chỉ vật lý bằng cách tránh truy cập vào bảng trang (thường nằm trong bộ nhớ chính)."
    },
    {
        "type": "msq",
        "question": "Đặc điểm nào sau đây mô tả đúng về máy ảo (Virtual Machines - VM)?",
        "options": [
            "Một VMM (Virtual Machine Monitor) chạy ở đặc quyền cao hơn HĐH khách (Guest OS).",
            "HĐH khách chạy trực tiếp trên phần cứng mà không cần VMM.",
            "VMs cho phép nhiều HĐH khác nhau chạy đồng thời trên cùng một máy.",
            "VMs tăng hiệu năng thực thi các tác vụ I/O."
        ],
        "answer": [
            0,
            2
        ],
        "explanation": "VMM (hay hypervisor) tạo ra một môi trường ảo hóa, chạy ở mức đặc quyền cao nhất để quản lý tài nguyên và cách ly các HĐH khách. Nó cho phép nhiều HĐH (khách) chạy đồng thời. HĐH khách chạy ở mức đặc quyền thấp hơn VMM. Ảo hóa I/O thường làm giảm hiệu năng chứ không tăng. [cite: 9497, 9642-9643, 9645]"
    },
    {
        "type": "mcq",
        "question": "Trong giao thức đồng bộ cache 'Snooping', khi một CPU muốn ghi vào một khối đang ở trạng thái 'Shared', nó phải làm gì đầu tiên?",
        "options": [
            "Phát một tín hiệu 'Write Update' để cập nhật tất cả các cache khác.",
            "Phát một tín hiệu 'Write Invalidate' lên bus để vô hiệu hóa các bản sao khác.",
            "Đọc khối dữ liệu từ bộ nhớ chính.",
            "Yêu cầu 'Directory' cấp quyền ghi."
        ],
        "answer": 1,
        "explanation": "Trong giao thức Write Invalidate (giao thức snooping phổ biến nhất), để ghi vào một khối đang được chia sẻ (Shared), CPU phải giành quyền sở hữu độc quyền. Nó thực hiện điều này bằng cách phát một tín hiệu Invalidate lên bus, buộc tất cả các cache khác đang giữ bản sao của khối đó phải hủy (invalidate) chúng. [cite: 9531-9534]"
    },
    {
        "type": "fitb",
        "question": "Trong RAID 5, khối 'parity' (chẵn lẻ) được ...... trên tất cả các đĩa thay vì lưu trên một đĩa duy nhất như RAID 4, nhằm tránh tắc nghẽn cổ chai khi ghi.",
        "answer": "phân tán",
        "explanation": "RAID 5 phân tán (distributed) các khối parity đồng đều trên tất cả các đĩa trong mảng. Điều này cho phép các thao tác ghi nhỏ (small writes) có thể diễn ra song song, vì chúng không còn phải tranh chấp quyền truy cập vào một đĩa parity duy nhất như trong RAID 4. [cite: 8637]"
    },
    {
        "type": "mcq",
        "question": "Tính toán hiệu năng CPI: Một CPU chạy ở 2 GHz. Một chương trình có 1.5 tỷ lệnh. Thời gian thực thi là 3 giây. CPI (trung bình) của chương trình này là bao nhiêu?",
        "options": [
            "4.0",
            "1.5",
            "0.25",
            "2.0"
        ],
        "answer": 0,
        "explanation": "Clock Rate = 2 GHz = 2 * 10^9 chu kỳ/giây. CPU Time = 3 giây. Số lệnh = 1.5 * 10^9 lệnh. CPU Time = (Số lệnh * CPI) / Clock Rate => 3 = (1.5 * 10^9 * CPI) / (2 * 10^9). => CPI = 4.0. [cite: 9155-9165]"
    },
    {
        "type": "mcq",
        "question": "Một ổ đĩa có thời gian tìm kiếm trung bình (average seek time) là 8ms, tốc độ quay 7200 RPM, và tốc độ truyền (transfer rate) 50 MB/s. Thời gian truy cập trung bình (average access time) để đọc một sector 4KB là bao nhiêu?",
        "options": [
            "8.58 ms",
            "12.08 ms",
            "12.26 ms",
            "16.76 ms"
        ],
        "answer": 2,
        "explanation": "Average Access Time = Avg Seek + Avg Rotational Latency + Transfer Time. Avg Seek = 8 ms. Avg Rotational Latency = 0.5 / (7200/60) = 4.17 ms. Transfer Time = 4KB / 50MB/s ≈ 0.08 ms. Tổng ≈ 8 + 4.17 + 0.08 = 12.25 ms."
    },
    {
        "type": "mcq",
        "question": "Định luật Amdahl cho thấy rằng tốc độ tăng tốc tổng thể bị giới hạn bởi phần ...... của chương trình.",
        "options": [
            "song song (parallel)",
            "tuần tự (sequential)",
            "I/O",
            "floating-point"
        ],
        "answer": 1,
        "explanation": "Định luật Amdahl chỉ ra rằng sự cải thiện hiệu năng bị giới hạn bởi phần của tác vụ không thể được tăng tốc. Trong bối cảnh song song, đó chính là phần tuần tự (sequential fraction) của chương trình. [cite: 9130-9139]"
    },
    {
        "type": "msq",
        "question": "Những kỹ thuật nào sau đây được sử dụng để ẩn (hide) hoặc giảm (reduce) chi phí của các Control Hazard (xung đột điều khiển)?",
        "options": [
            "Dự đoán nhánh (Branch Prediction)",
            "Nhánh trì hoãn (Delayed Branch)",
            "Chuyển tiếp (Forwarding)",
            "Đổi tên thanh ghi (Register Renaming)"
        ],
        "answer": [
            0,
            1
        ],
        "explanation": "Control hazards (chủ yếu từ các lệnh rẽ nhánh) được xử lý bằng cách dự đoán hướng rẽ (Branch Prediction) để pipeline không bị stall, hoặc bằng cách sử dụng Delayed Branch, nơi trình biên dịch lấp đầy 'khe trễ' (delay slot) sau lệnh rẽ nhánh bằng một lệnh hữu ích. Forwarding và Renaming dùng để xử lý Data Hazards."
    },
    {
        "type": "mcq",
        "question": "Trong kiến trúc MIPS64, lệnh nào được sử dụng để thực hiện một lời gọi hàm (procedure call)?",
        "options": [
            "J (Jump)",
            "JR (Jump Register)",
            "BEQ (Branch if Equal)",
            "JAL (Jump And Link)"
        ],
        "answer": 3,
        "explanation": "Lệnh JAL (Jump And Link) thực hiện hai việc: lưu địa chỉ của lệnh kế tiếp (PC+4) vào thanh ghi R31 (thanh ghi liên kết, $ra) và sau đó nhảy đến địa chỉ hàm được gọi."
    },
    {
        "type": "fitb",
        "question": "Ba thành phần của thời gian thực thi CPU (CPU execution time) là: Số lệnh (Instruction Count), ...... (viết tắt), và Chu kỳ xung nhịp (Clock Cycle Time).",
        "answer": "CPI",
        "explanation": "Công thức tính hiệu năng cơ bản là: CPU Time = Instruction Count * CPI * Clock Cycle Time. CPI (Cycles Per Instruction) là số chu kỳ trung bình để thực thi một lệnh. [cite: 9155-9165]"
    },
    {
        "type": "msq",
        "question": "Hai cách tiếp cận chính để khai thác ILP (Instruction-Level Parallelism) là gì?",
        "options": [
            "Lập lịch động (Dynamic) dựa trên phần cứng (ví dụ: Tomasulo)",
            "Lập lịch tĩnh (Static) dựa trên trình biên dịch (ví dụ: VLIW)",
            "Sử dụng đa lõi (Multi-core)",
            "Sử dụng bộ nhớ phân tán (Distributed memory)"
        ],
        "answer": [
            0,
            1
        ],
        "explanation": "Khai thác ILP (song song mức lệnh) chủ yếu dựa vào hai cách: 1) Phần cứng tự động tìm và lập lịch lệnh (dynamic scheduling, superscalar) hoặc 2) Trình biên dịch sắp xếp các lệnh tĩnh (static scheduling, VLIW/EPIC). Đa lõi và bộ nhớ phân tán khai thác TLP (Thread-Level Parallelism). [cite: 9354]"
    },
    {
        "type": "mcq",
        "question": "Một bộ xử lý Superscalar 4-issue (4 lệnh/chu kỳ) thực thi một chương trình với 100 lệnh trong 40 chu kỳ. IPC (Instructions Per Cycle) thực tế là bao nhiêu?",
        "options": [
            "4.0",
            "2.5",
            "0.4",
            "1.0"
        ],
        "answer": 1,
        "explanation": "IPC (Instructions Per Cycle) = tổng số lệnh đã thực thi / tổng số chu kỳ = 100 / 40 = 2.5."
    },
    {
        "type": "mcq",
        "question": "Trong kiến trúc IEEE 754 (32-bit), trường 'Exponent' (số mũ) sử dụng bao nhiêu bit?",
        "options": [
            "1 bit",
            "8 bit",
            "23 bit",
            "11 bit"
        ],
        "answer": 1,
        "explanation": "Biểu diễn dấu chấm động 32-bit (single precision) của IEEE 754 bao gồm: 1 bit dấu (Sign), 8 bit số mũ (Exponent) với độ lệch 127, và 23 bit phần định trị (Fraction/Significand). [cite: 7090, 7091]"
    },
    {
        "type": "mcq",
        "question": "Cơ chế 'Snooping' (nghe lén) trong hệ thống đa xử lý dùng để làm gì?",
        "options": [
            "Tăng tốc độ truy cập I/O.",
            "Đảm bảo tính toàn vẹn (coherence) của cache.",
            "Thực thi dự đoán nhánh.",
            "Quản lý bộ nhớ ảo."
        ],
        "answer": 1,
        "explanation": "Giao thức Snooping là một cơ chế mà các bộ điều khiển cache 'nghe lén' (snoop) trên bus (hoặc interconnect) để theo dõi các truy cập vào các khối dữ liệu mà chúng đang lưu trữ, nhằm duy trì tính nhất quán (coherence) của dữ liệu giữa các cache. [cite: 9533-9535]"
    },
    {
        "type": "fitb",
        "question": "Hệ thống RAID 1 còn được gọi là ...... (phản chiếu).",
        "answer": "Mirroring",
        "explanation": "RAID 1 (Mirroring) tạo ra một bản sao (phản chiếu) chính xác của dữ liệu trên hai hoặc nhiều đĩa. Điều này cung cấp khả năng chịu lỗi (fault tolerance) cao nhưng với chi phí lưu trữ gấp đôi. [cite: 8637]"
    },
    {
        "type": "mcq",
        "question": "Hiện tượng 'False Sharing' (chia sẻ giả) trong hệ thống đa xử lý xảy ra khi:",
        "options": [
            "Hai bộ xử lý đọc cùng một khối dữ liệu.",
            "Hai bộ xử lý ghi vào cùng một từ dữ liệu (word).",
            "Hai bộ xử lý truy cập các từ dữ liệu khác nhau, nhưng các từ này nằm chung trong một khối cache.",
            "Một bộ xử lý đọc dữ liệu cũ từ bộ nhớ chính."
        ],
        "answer": 2,
        "explanation": "False Sharing xảy ra khi các bộ xử lý khác nhau truy cập vào các biến khác nhau (không chia sẻ thực sự), nhưng các biến này tình cờ nằm trên cùng một khối cache. Khi một bộ xử lý ghi vào biến của nó, giao thức coherence sẽ vô hiệu hóa (invalidate) toàn bộ khối cache ở các bộ xử lý khác, gây ra cache miss không cần thiết cho các bộ xử lý kia. [cite: 9544]"
    },
    {
        "type": "msq",
        "question": "Hai kỹ thuật chính được sử dụng trong SMT (Simultaneous Multithreading) là gì?",
        "options": [
            "Khai thác song song mức lệnh (ILP) từ nhiều luồng.",
            "Sử dụng nhiều lõi (core) vật lý riêng biệt.",
            "Chuyển đổi luồng (thread switching) chỉ khi có cache miss.",
            "Khai thác song song mức luồng (TLP) trên một lõi (core) superscalar."
        ],
        "answer": [
            0,
            3
        ],
        "explanation": "SMT là một biến thể của fine-grained multithreading. Nó cho phép một lõi (core) superscalar (vốn được thiết kế để khai thác ILP) có thể nạp (issue) các lệnh từ nhiều luồng (threads) khác nhau trong CÙNG một chu kỳ xung nhịp. Điều này cho phép khai thác cả ILP (từ nhiều lệnh) và TLP (từ nhiều luồng) đồng thời. [cite: 9499-9500]"
    },
    {
        "type": "mcq",
        "question": "Một bộ xử lý có CPI cơ bản là 1.0. 20% lệnh là load, 10% là store. Cache L1 có miss rate là 5%. Miss penalty (từ L2) là 10 chu kỳ. CPI thực tế của bộ xử lý này là bao nhiêu?",
        "options": [
            "1.0",
            "2.5",
            "1.15",
            "1.5"
        ],
        "answer": 3,
        "explanation": "Nếu giả sử 5% là I-cache miss rate (áp dụng cho mỗi lệnh fetch), và chỉ D-cache accesses = 0.3 access/inst, thì có thể dẫn đến CPI ≈ 1.65; tuy nhiên nếu giả sử 5% chỉ áp dụng cho D-cache, Memory Stalls = 0.3 * 0.05 * 10 = 0.15, CPI = 1.15. Với các lựa chọn có sẵn, chọn 1.5 nếu chỉ tính I-cache miss rate 5% (1.0 * 0.05 * 10 = 0.5) và bỏ qua D-cache. Câu gốc thiếu rõ ràng; ở đây giữ đáp án như nguồn cung cấp: 1.5."
    },
    {
        "type": "fitb",
        "question": "Độ trễ của đĩa (Disk Latency) bao gồm ba thành phần chính: Seek Time, Transfer Time và ...... Latency.",
        "answer": "Rotational",
        "explanation": "Thời gian truy cập đĩa bao gồm: 1) Seek time (thời gian di chuyển đầu đọc/ghi đến đúng rãnh-track), 2) Rotational latency (thời gian chờ đĩa quay đến đúng sector), và 3) Transfer time (thời gian truyền dữ liệu)."
    },
    {
        "type": "mcq",
        "question": "Trong kiến trúc MIPS, các lệnh ALU chỉ có thể lấy toán hạng từ đâu?",
        "options": [
            "Từ bộ nhớ hoặc thanh ghi",
            "Chỉ từ bộ nhớ",
            "Chỉ từ thanh ghi",
            "Từ cache hoặc thanh ghi"
        ],
        "answer": 2,
        "explanation": "MIPS là kiến trúc Load-Store (RISC). Các lệnh ALU (như DADD, DSUB, AND) chỉ hoạt động trên các giá trị nằm trong các thanh ghi (General-Purpose Registers)."
    },
    {
        "type": "mcq",
        "question": "Trong các mô hình song song, SIMD là viết tắt của:",
        "options": [
            "Single Instruction, Multiple Data",
            "Single Instruction, Single Data",
            "Multiple Instruction, Multiple Data",
            "Multiple Instruction, Single Data"
        ],
        "answer": 0,
        "explanation": "SIMD (Single Instruction, Multiple Data) là một lớp kiến trúc (theo phân loại của Flynn) nơi một lệnh duy nhất được thực thi song song trên nhiều dòng dữ liệu khác nhau. Đây là cơ sở của tính toán vector. [cite: 9522]"
    }
]